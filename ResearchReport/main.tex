%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The Legrand Orange Book
% LaTeX Template
% Version 2.1.1 (14/2/16)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Mathias Legrand (legrand.mathias@gmail.com) with modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
% Compiling this template:
% This template uses biber for its bibliography and makeindex for its index.
% When you first open the template, compile it from the command line with the 
% commands below to make sure your LaTeX distribution is configured correctly:
%
% 1) pdflatex main
% 2) makeindex main.idx -s StyleInd.ist
% 3) biber main
% 4) pdflatex main x 2
%
% After this, when you wish to update the bibliography/index use the appropriate
% command above and make sure to compile with pdflatex several times 
% afterwards to propagate your changes to the document.
%
% This template also uses a number of packages which may need to be
% updated to the newest versions for the template to compile. It is strongly
% recommended you update your LaTeX distribution if you have any
% compilation errors.
%
% Important note:
% Chapter heading images should have a 2:1 width:height ratio,
% e.g. 920px width and 460px height.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[11pt,fleqn]{book} % Default font size and left-justified equations

\usepackage[toc,page]{appendix}
%----------------------------------------------------------------------------------------

\input{structure} % Insert the commands.tex file which contains the majority of the structure behind the template

\newcommand{\arnaud}[1]{\textcolor{red}{$<$ #1 $>$}}

\begin{document}

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\begingroup
\thispagestyle{empty}
\begin{tikzpicture}[remember picture,overlay]
\coordinate [below=12cm] (midpoint) at (current page.north);
\node at (current page.north west)
{\begin{tikzpicture}[remember picture,overlay]
% \node[anchor=north west,inner sep=0pt] at (0,0) {\includegraphics[width=\paperwidth]{background}}; % Background image
\draw[anchor=north] (midpoint) node [fill=ocre!30!white,fill opacity=0.6,text opacity=1,inner sep=1cm]{\Huge\centering\bfseries\sffamily\parbox[c][][t]{\paperwidth}{\centering Research report\\[15pt] % Book title
% {\Large A Profound Subtitle}\\[20pt] % Subtitle
{\Large Arnaud Bletterer}}}; % Author name
\end{tikzpicture}};
\end{tikzpicture}
\vfill
\endgroup

%----------------------------------------------------------------------------------------
%	COPYRIGHT PAGE
%----------------------------------------------------------------------------------------

\newpage
~\vfill
\thispagestyle{empty}

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

\usechapterimagefalse % If you don't want to include a chapter image, use this to toggle images off - it can be enabled later with \usechapterimagetrue

\chapterimage{chapter_head_1.pdf} % Table of contents heading image

\pagestyle{empty} % No headers

\tableofcontents % Print the table of contents itself

\cleardoublepage % Forces the first chapter to start on an odd page so it's on the right

\pagestyle{fancy} % Print headers again

%----------------------------------------------------------------------------------------
%	CHAPTER 2
%----------------------------------------------------------------------------------------

\chapter{Semi-regular Surface Reconstruction}

This chapter explains a new method in surface reconstruction, based on the original data coming from many 3D scanners, namely depthmaps.

\section{Depthmaps}
Depthmaps are 2D grayscale images, representing the distance from points to the scene. They are a discrete local parameterization of the scene acquired using the scanners.

\subsection{Depthmaps reprojection}
There are many different methods to recover 3D positions from depthmaps, depending on the acquisition devices.

\subsubsection{LiDAR scanners}
For LiDAR scanners for example, it is common to use spherical coordinates to store values in the depthmaps.
Spherical coordinates \cite{Wal67} are a coordinate system used to define positions over a sphere. 
They define $\theta$ to be the azimuthal angle $0 \leq \theta < 2\pi$ from the x-axis, $\phi$ to be polar angle (zenithal angle) $0 \leq \phi \leq \pi$ and $r$ to be the distance (radius) from a point to the origin $r \in [0;+\infty)$.

They are obtained from Cartesian coordinates by the following relations : 

\begin{equation}
\label{eq:cartesian_to_spherical}
	r = \sqrt{x^2 + y^2 + z^2} \\
	\theta = \tan^{-1}(\frac{y}{x})\\
	\phi = \cos^{-1}(\frac{z}{r}),
\end{equation}

and Cartesian coordinates can be recovered from those using : 

\begin{equation}
\label{eq:spherical_to_cartesian}
	x = r\cos\theta\sin\phi\\
	y = r\sin\theta\sin\phi\\
	z = r\cos\phi
\end{equation}

In the depthmap, the intensity stored for each pixel is the value of $r$. Knowing $\Delta\theta$ and $\Delta\phi$ (representing the difference of azimuthal and polar angles respectively between two consecutive points), one can recover $\theta$ and $\phi$ for each pixel of the depthmap, taking in consideration the structure of the depthmaps (2D matrices). 
Using Equation\eqref{eq:spherical_to_cartesian}, it is possible to recover 3D positions of points from intensity values contained in the depthmaps.

\section{Border marking, labeling and routing}
\label{sec:border_marking}

This link between depth values and 3D coordinates motivated us using depthmaps as a parameterization domain to apply algorithm on point clouds, considering the implicit connectivity between pixels to do local computations requesting the consideration of neighboring points.

If most of the time it is correct to consider that neighboring pixels in a depthmap are also neighbors on the surface (with respect to the sampling density of the acquisition), it is not the case along depth discontinuities.
Since an acquisition is done from a specific position and orientation, they can only represent visible points from that specific point of view. Thus many surface areas can be occluded, and different surface areas could be considered touching each other in the depthmap.

To avoid this, we present a method to mark the borders, identify each of them uniquely and store the path from the beginning until the end of each border.

\subsection{Border marking}
First, we mark all the pixels of the depthmap that do not fulfill a local depth-discontinuity condition. We consider a depth-discontinuity as being an important change of depth in at least one direction (horizontal, vertical or diagonal).

During that step, we are defining how points would be triangulated if a mesh was to be constructed between neighboring pixels over the whole depthmap. For this, we consider an arbitrary connectivity pattern, connecting one pixel to 6 of its neighbors, and will use that pattern to consider the possible neighbors of a point \arnaud{ADD FIGURE CONNECTIVITY}. This pattern will be used during the following neighborhood considerations.

We will mark both pixels along the border, meaning that those borders are 

For each pixel $p$, we search to know if there a high intensity variation with respect to its neighborhood. If this is the case, it means that the pixels do not belong the same surface area, and then need to be separated for the further processings.
We consider that each pixel has at least one neighbor in each direction belonging to the same surface area (low intensity variation). Knowing that, we evaluate how much difference there is between the 2 neighbors in each direction (top and bottom, left and right, bottom-right and top-left.
For this, we compute a mean intensity variation (MIV) per direction, by dividing the intensity of the current pixel with the one of each neighbor belonging to that direction. We consider that if the variation of intensity between $p$ and one of his neighbor is over the associated MIV (+ or - $k$\%), then there exists a border between $p$ and this specific neighbor. In all of our experiments we used $k = 3$ and found it to give good results.

Since this is a highly parallelizable algorithm (each operation is executed indepently for each pixel), we implemented it using GPGPU methods. This makes the computation of the borders really fast.

\subsection{Border labeling and routing}
Now that borders have been indentified, we need to label them in order to be able to consider them independently. 

Each border is represented as a list, characterizing the path from pixel to pixel, from the beginning until the end of the border.

We decide to use a region-growing process. Starting from a pixel that has been marked as a border, we try to find the next pixel defining the same border. When we consider the global triangulation over the depthmap, we search the next vertex along the border of the triangulation, considering oriented faces.
When this vertex has been found, it is added to the current border list, and being processed, to find the next pixel of the border after him.
When there is no more pixel than can be added to the current border, the border is considered as complete.

At the initialization, every pixel marked as a border is added to a list. Until the list is not empty the first pixel is treated and removed from the list. If the pixel has already been labeled, then it is ignored, and the next one is considered instead. If the pixel isn't already labeled it is used as the starting pixel from the algorithm described above.

\section{Poisson-disk sampling of the depthmap}
\label{sec:poisson_sampling}

In semi-regular triangle remeshing, to construct a semi-regular mesh from an irregular one, one method consists in constructing a base mesh, i.e. a low resolution version of the irregular one and subdividing it recursively (and projecting the generated vertices onto the original surface) \cite{PRS15}. Our work is inspired by those methods, to construct the base mesh by sampling the depthmap (which is a discrete representation of the acquired surface).

To obtain a good distribution of the base vertices over the depthmap, we use a poisson-disk sampling, as it has been shown to be one of the best sampling patterns for many applications. 
We use a dart-throwing approach to choose the samples, combined with an region-growing process through Dijkstra's algorithm \cite{Dij59} to compute the disks areas.

To preserve the holes that have been detected, we first sample each border. We take 3 samples per border, this ensures that every hole (which is delimited by a border, by construction) will be preserved during the generation of the initial triangulation.

Then, we compute a connectivity graph over the depthmap. Each pixel can have up to 6 neighbors (with respect to the triangulation pattern chosen at the beginning).
An egde exists between two pixels if they are not separated by a border.

\subsection{Uniform sampling}
This method uses the 3D coordinates of points (which are reprojected pixels) and weights each edge using the euclidean distance between both points.
By using Dijkstra's algorithm, we can approximate geodesic distances. 
By using this method, we consider Poisson disks (surface patches to be more precise) to have an equal area in 3D.

\arnaud{INSERT IMAGE UNIFORM SAMPLING}

\subsection{Density adaptive sampling}
Depthmaps can represent scenes having a really huge difference in sampling density, depending on the distance of a surface area to the scanner. 
For example, on the (Figure \arnaud{ADD FIGURE DIFFERENCE OF SAMPLING}) points in the green area have a sampling density of \arnaud{sampling density value w.r.t Bbox} and the pixels in the blue area have a sampling density of \arnaud{sampling density value w.r.t Bbox}. It can be interesting to conserve that difference of density when choosing the samples, in order to keep the precision of the original acquisition, when fine structures have been acquired.

Instead of sampling a point cloud uniformly in 3D, we suggest to take the local sampling density into account. In other words, rather than computing disks with constant radius, we constrain each disk to contain a constant number of points.
Interestingly, this can easily be obtained by sampling the depthmap without considering 3D geodesic distances, i.e. doing a classical poisson-disk sampling on an discretized planar domain.

\arnaud{INSERT IMAGE DENSITY ADAPTIVE SAMPLING}

\subsection{Curvature adaptive sampling}
In order to obtain a better sampling of the surface, and acquiring precise details during the acquisition, it would be interesting to sample more densely the surface areas where the absolute Gaussian curvature is high (representing high changes in the normal field). For this, the idea is to consider the "normalized" Gaussian curvature as probability density function, giving a higher probability to points in areas of high absolute curvature, and a lower probability to points in areas of low absolute curvature.

\arnaud{INSERT GEOMETRIC GAUSSIAN CURVATURE ADAPTIVE SAMPLING}

\section{Voronoi diagram generation and Lloyd relaxation}
\label{sec:lloyd_relaxation}

In order to even the sites positions, we apply a Lloyd relaxation scheme based on 3D geodesic distances, using the connectivity of the depthmap.
This algorithm is decomposed into two steps : 
\begin{itemize}
	\item Computing a voronoi diagram, determining for each site $s_i$ the closest points from $s_i$ to any other site.
	\item Moving the position of each site $s$
\end{itemize}

Those steps are repeated until the sites stop moving (in practice, the process is stopped when the mean displacement is below a given threshold).

\subsection{Voronoi diagram generation}
Voronoi diagrams \arnaud{(add citation)} are a partition of a space $\mathbb{R}^d$ in a set of convex cells $Vor_S(v_i)$ from $k$ sites where every element contained in the cell $Vor_S(v_i)$ is closer from the site $v_i$ than from any other site $v_j$

\begin{equation}
\label{eq:voronoi_cell}
	Vor_S(v_i) = \{ x \in \mathbb{R}^d, \forall p \in S d(v_i,p) \leq d(v_j,p), j \neq i\},
\end{equation}

where $d$ is a distance metric. Generally, Euclidean distance metric are used to partition the domain, however it is possible to use other distance metrics, that could be more representative when dealing with 3D surfaces for example.

To compute a Voronoi diagram over the depthmap, we use a discrete approach, through the multi-sources Dijkstra's algorithm (MSSP) \cite{Dij59} which finds for a vertex of a graph, the shortest path through the graph between this vertex and any other vertex in the graph.
We adapted a GPU implementation from the work of \cite{PPA16} to include the use of depthmaps.

This method works as a recursive process. 
At the beginning, each site is marked as belonging to its own voronoi cell, and marked as "ready" to propagate its ownership.
Throughout the algorithm every pixel will store its accumulated distance from the site of the Voronoi cell it belongs to. 
At the initialization this distance is set to infinity for every valid pixel of the depthmap, and set to 0 for every non-valid pixel.
This defines the domain of the Voronoi diagram computation

Every pixel marked $p$ will check its 1-ring neighborhood and for every neighbor $p_i$, if the currently stored distance for $p_i$ $d(p_i)$ is superior to the distance stored at $p$ plus the 3D Euclidian distance between $p$ and $p_i$. 
If it is the case, $p_i$ will be considered as belonging to the same cell as $p$, its stored distance being updated accordingly and it is marked as "ready" to propagate its ownership.

The algorithm stops when no pixel is marked anymore.

\subsubsection{Voronoi diagram verifications}
In \cite{Gus07}, verifications have been added in order to ensure that the generation of a surfacic voronoi partition was generating a manifold mesh.
He decided to verify 5 different topological conditions over the configurations of Voronoi tiles (Figure \ref{fig:voronoi_conditions}) : 
\begin{itemize}
	\item \textit{Encrouched boundaries}. A Voronoi tile that touches a surface boundary has to have its seed on that boundary. 
	If this condition fails a new seed is introduced on the boundary of the surface within the current tile
	\item \textit{Nonzero genus}. A Voronoi tile needs to have zero genus. If this condition fails, a new seed is introduced at a vertex adjacent to the seed vertex of the tile.
	\item \textit{Multiple tile boundary components}. The boundary of a Voronoi tile can only consist of a single connected component. If this condition fails a new seed is introduced at a vertex adjacent to the seed vertex of the tile.
	\item \textit{Single curve tile boundaries}. A Voronoi tile that is adjacent to other tiles should not have more than one neighbor along each tile boundary curve. If this condition fails a new seed is introduced at a vertex adjacent to the tile boundary curve.
	\item \textit{Multiple neighbor instances}. Any pair of Voronoi tiles cannot touch along more than a single tile boundary curve. If this condition fails, a new seed is introduced at a vertex adjacent to the shorter among the offending tile boundary curves.
\end{itemize}

\begin{figure}[ht]
\centering\includegraphics[scale=0.4]{VoronoiConditions}
\caption{Conditions that the Voronoi diagram has to respect in order to generate a 2-manifold triangulation \cite{Gus07}}
\label{fig:voronoi_conditions}
\end{figure}

In our case, some configurations cannot happen, since depth-maps can only represent the visible areas of a scene from a specific pont of view.
For example, the \textit{Multiple neighbor instances} cannot happen.

Those conditions are verified after each Voronoi diagram computation. 

\subsubsection{Power diagram from Gaussian curvature}
Power diagrams are an extension of Voronoi diagrams to represent the fact that some sites can have a higher importance than others, for them to cover a larger area with respect to their neighbors. Similarly to what has been done for the poisson sampling in Sec.\ref{sec:poisson_sampling}, where the probability density function has been weighted by the absolute Gaussian curvature of the surface, it is possible to weight the influence of the Voronoi sites by the absolute Gaussian curvature, in order to create smaller cells (smaller weight) around the surface areas which have a high absolute curvature.

\begin{equation}
\label{eq:power_cell}
	Vor_S(v_i) = \{ x \in \mathbb{R}^d, \forall p \in S \norm{v_i-p}_d - w_i \leq \norm{v_j-p} - w_j\}
\end{equation}

\subsection{Lloyd relaxation}
Now that each valid pixel of the depthmap is included in a Voronoi cell, sites are going to be moved, in order for them to be more evenly spaced locally.

Each Voronoi cell can be in two different configurations : 
\begin{itemize}
	\item \textbf{the cell doesn't touch a border}. This means that no pixel being part of the Voronoi cell belongs to the border.
	In this configuration, the cell's site is moved to the centroid of its cell
	\item \textbf{the cell touches a border}. This means that at least one pixel being part of the Voronoi cell belongs to the border.
	In this configuration, the cell's site is moved to the closest pixel belonging to the border to the centroid of its cell (in the least squares sense).
\end{itemize}

Mathematically speaking, we consider a probability density function $\rho(y)$ defined over the domain. 
Every element belonging to a border is associated an infinite weight. Other elements are given a constant weight.
This moves the centroid of every cell touching a border on the middle of that border.

\begin{equation}
	z^* = \frac{\int_V y\rho(y)\,dx}{\int_V \rho(y)\,dx},
\end{equation}

where $z^*$ is the centroid of the Voronoi cell $V$.

However, we can use another function as a probability density function. For example we can use the Gaussian curvature of the surface (App.\ref{sec:gaussian_curvature}).
Considering this function, we want to give a higher probability to the areas of higher absolute Gaussian curvature, and a lower probability to the areas of lower absolute Gaussian curvature. This means that the weights should be proportional to the the normalized Gaussian curvature, i.e. the pixels having the higher Gaussian curvature will have a bigger weight than the areas of lower Gaussian curvature.

\section{Surface triangulation}
\label{sec:surface_triangulation}
Before triangulating, we need to define whether Voronoi cells belong to the same neighborhood (same surface area) or not. 
For this we will use the border that was constructed in \ref{sec:border_marking}.
We consider that two Voronoi cells are belonging to the same neighborhood if there is at one "non-border" pixel in one of those cells that belongs to the 1-ring neighborhood of a non-vorder pixel of the other cell.

\arnaud{ADD FIGURE VORONOI CELL NEIGHBORHOOD}

\section{Surface subdivision}
\label{sec:surface_subdivision}
Now that the coarse triangulation has been generated, the idea is to recursively subdivide it to obtain a better approximation of the acquired surface.
Many face subdivision schemes exist, they are separated into two families, the interpolating and the approximating ones :

\textbf{Approximating schemes}
\begin{itemize}
	\item Catmull-Clark subdivision
	\item Doo-Sabin subdivision
	\item Loop subdivision
	\item Mid-Edge subdivision
	\item $\sqrt(3)$ subdivision
\end{itemize}

\textbf{Interpolating schemes}
\begin{itemize}
	\item Butterfly subdivision
	\item 
\end{itemize}

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------
\bibliographystyle{alpha}
\bibliography{bibliography}

\printindex

\begin{appendices}
\section{Gaussian curvature}
\label{sec:gaussian_curvature}
The Gaussian curvature $K$ of a surface $S$ at a point $p$ is the product of the principal curvatures, $\kappa_1$ and $\kappa_2$ :

\begin{equation}
	K = \kappa_1\kappa_2
\end{equation}

Principal curvatures measure how much the surface bends in the two orthogonal directions where the surface bends the most.

The Gaussian curvature is an intrinsic measure of the curvature of a surface. 
As stated by Gauss in \cite{Gau28} through his \textit{theorema egregium}, the Gaussian curvature of an embedded smooth surface in $\mathbb{R}^3$ is invariant under local isometries.
This means that no matter how the surface is bent, its total Gaussian curvature remains the same, and is related to the Euler Characteristic, based on the topology of the surface.

\subsection{Gaussian curvature approximation}
In \cite{MMPB02}, an approximation of Gaussian curvature is given by using the vertex angular deficit expression :

\begin{equation}
	K(v_i) = \frac{2\pi -\sum_{v_j \in \mathcal{N}_1(v_i)} \theta_{ij}}{\mathcal{A}_{mixed}},
\end{equation}

where $\mathcal{N}_1$ represents the 1-ring neighborhood of $v_i$, $\theta_{ij}$ is the angle of $v_jv_iv_{j-1}$ at $v_i$ which is given by the following formula : 

\begin{equation}
	\theta_{ij} = \arccos(\frac{\overrightarrow{v_iv_j} \cdot \overrightarrow{v_i v_{j-1}}}
	{\norm{\overrightarrow{v_iv_j}}^2\norm{\overrightarrow{v_iv_{j-1}}}^2}),
\end{equation} 

and $\mathcal{A}_{mixed}$ represents the surface area around the vertex $v_i$ : 

\begin{algorithm}
\caption{$\mathcal{A}_{mixed}$ computation}
\begin{algorithmic}
\State $\mathcal{A}_{mixed}$ = 0
\ForAll{triangle $T$ from the 1-ring neighborhood of x}
	\If{T is non-obtuse}	//Voronoi area can be considered
		\State $\mathcal{A}_{mixed} \mathrel{+}= \frac{1}{8} \sum\limits_{v_j \in N_1(v_i)} (\cot \alpha_{ij} + \cot \beta_{ij}) \norm{v_i-v_j}^2$
	\Else
		\If{the angle of $T$ at $x$ is obtuse}
			\State $\mathcal{A}_{mixed} \mathrel{+}= area(T)/2$
		\Else
			\State $\mathcal{A}_{mixed} \mathrel{+}= area(T)/4$
		\EndIf
	\EndIf
\EndFor
\end{algorithmic}
\end{algorithm}

\arnaud{ADD FIGURE GAUSSIAN CURVATURE}

\section{Proofs}

\begin{equation}
	y_i = \frac{\int_{V_i}xf(x)dx}{\int_{V_i}f(x)dx},
\end{equation}

where : 

\begin{equation}
	f(x) = 
    \begin{cases}
      \frac{1-\epsilon}{|B_{V_i}||C|}, & \text{if}\ x \in B_{V_i} \\
      \frac{\epsilon}{(|V_i|-|B_{V_i}|)|C|}, & \text{if}\ x \not\in B_{V_i}
    \end{cases}
\end{equation}

\begin{equation}
	\sum_{i=1}^k \int_{V_i}f(x)dx = 1
\end{equation}

\begin{align*}
	\sum_{i=1}^k \int_{V_i}f(x)dx 
	&= \int_{V_i \setminus B_{V_i}}\frac{\epsilon}{(|V_i|-|B_{V_i}|)|C|}dx + \int_{B_{V_i}}\frac{1-\epsilon}{|B_{V_i}||C|}dx \\
	&= \frac{\epsilon}{(|V_i|-|B_{V_i}|)|C|}\int_{V_i \setminus B_{V_i}}dx + \frac{1-\epsilon}{|B_{V_i}||C|}\int_{B_{V_i}}dx \\
	&= \frac{1}{|C|}(\frac{\epsilon}{|V_i|-|B_{V_i}|}\int_{V_i \setminus B_{V_i}}dx + \frac{1-\epsilon}{|B_{V_i}|}\int_{B_{V_i}}dx)
\end{align*}

\end{appendices}

%----------------------------------------------------------------------------------------

\end{document}
